{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZdPIqHUqvzVt",
        "outputId": "37266410-fb31-454a-8603-ea2bd933ecc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Statsforecast\n",
            "  Using cached statsforecast-1.7.5-py3-none-any.whl (133 kB)\n",
            "Collecting Mlforecast\n",
            "  Using cached mlforecast-0.13.0-py3-none-any.whl (65 kB)\n",
            "Collecting neuralforecast\n",
            "  Downloading neuralforecast-1.7.2-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nixtla\n",
            "  Downloading nixtla-0.5.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from Statsforecast) (2.2.1)\n",
            "Collecting coreforecast>=0.0.9 (from Statsforecast)\n",
            "  Downloading coreforecast-0.0.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.5/223.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from Statsforecast) (0.58.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from Statsforecast) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from Statsforecast) (2.0.3)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from Statsforecast) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from Statsforecast) (0.14.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Statsforecast) (4.66.4)\n",
            "Collecting fugue>=0.8.1 (from Statsforecast)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting utilsforecast>=0.1.4 (from Statsforecast)\n",
            "  Downloading utilsforecast-0.1.11-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from Statsforecast) (3.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from Mlforecast) (2023.6.0)\n",
            "Collecting optuna (from Mlforecast)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Mlforecast) (24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from Mlforecast) (1.2.2)\n",
            "Collecting window-ops (from Mlforecast)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.3.0+cu121)\n",
            "Collecting pytorch-lightning>=2.0.0 (from neuralforecast)\n",
            "  Downloading pytorch_lightning-2.3.0-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.2/812.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray[tune]>=2.2.0 (from neuralforecast)\n",
            "  Downloading ray-2.30.0-cp310-cp310-manylinux2014_x86_64.whl (66.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from nixtla)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from nixtla) (2.7.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nixtla) (2.31.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from nixtla) (8.4.1)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.8.1->Statsforecast)\n",
            "  Downloading triad-0.9.7-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting adagio>=0.2.4 (from fugue>=0.8.1->Statsforecast)\n",
            "  Downloading adagio-0.2.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.0->Statsforecast) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->Statsforecast) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->Statsforecast) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->Statsforecast) (2024.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=2.0.0->neuralforecast)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.12.2)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning>=2.0.0->neuralforecast)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.15.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.4.1)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune]>=2.2.0->neuralforecast)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (14.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->Statsforecast) (0.5.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->neuralforecast)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->nixtla) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->nixtla) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx->nixtla)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->nixtla) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->nixtla) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->nixtla)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna->Mlforecast)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna->Mlforecast)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->Mlforecast) (2.0.30)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->nixtla) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->nixtla) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nixtla) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nixtla) (2.0.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->Mlforecast) (1.4.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->Mlforecast)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->Mlforecast) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=2.0.0->neuralforecast) (67.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.13.2->Statsforecast) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->Mlforecast) (3.0.3)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.8.1->Statsforecast)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->nixtla) (1.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->neuralforecast) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.18.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->neuralforecast) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->Mlforecast) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->Mlforecast) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->Mlforecast) (4.0.3)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.8.1->Statsforecast)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: appdirs, tensorboardX, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, lightning-utilities, h11, fs, coreforecast, colorlog, window-ops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, alembic, utilsforecast, triad, optuna, nvidia-cusolver-cu12, httpx, ray, nixtla, Mlforecast, adagio, torchmetrics, fugue, Statsforecast, pytorch-lightning, neuralforecast\n",
            "Successfully installed Mako-1.3.5 Mlforecast-0.13.0 Statsforecast-1.7.5 adagio-0.2.4 alembic-1.13.1 appdirs-1.4.4 colorlog-6.8.2 coreforecast-0.0.10 fs-2.4.16 fugue-0.9.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 lightning-utilities-0.11.2 neuralforecast-1.7.2 nixtla-0.5.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 pytorch-lightning-2.3.0 ray-2.30.0 tensorboardX-2.6.2.2 torchmetrics-1.4.0.post0 triad-0.9.7 utilsforecast-0.1.11 window-ops-0.0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsforecast/core.py:27: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mlforecast.models'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-94077ff48181>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsforecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoARIMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlforecast\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLForecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlforecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuralforecast\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuralForecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuralforecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNBEATS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoNBEATS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlforecast.models'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import AutoARIMA, ETS, AutoETS, ARIMA\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.models import RandomForest\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.models import NBEATS, AutoNBEATS\n",
        "from nixtlats import TimeGPT\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "data = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
        "data.columns = ['Passengers']\n",
        "\n",
        "# Split the data\n",
        "test_size = 24\n",
        "train_data = data[:-test_size]\n",
        "test_data = data[-test_size:]"
      ],
      "metadata": {
        "id": "5kG9WWVFv94W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models to be used\n",
        "models = {\n",
        "    'ARIMA': ARIMA,\n",
        "    'AutoARIMA': AutoARIMA,\n",
        "    'AutoETS': AutoETS,\n",
        "    'RandomForest': RandomForest,\n",
        "    'NBEATS': NBEATS,\n",
        "    'AutoNBEATS': AutoNBEATS,\n",
        "}\n",
        "\n",
        "forecasts = {h: {} for h in [3, 6, 12]}\n",
        "errors = {metric: {h: {} for h in [3, 6, 12]} for metric in ['RMSE', 'sMAPE', 'RMSSE']}\n",
        "train_times = {}\n",
        "model_params = {}"
      ],
      "metadata": {
        "id": "d6uf8bdtwMxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rolling-origin forecast\n",
        "def rolling_origin_forecast(model, train_data, test_data, horizon):\n",
        "    history = train_data.copy()\n",
        "    predictions = []\n",
        "    while len(history) + horizon <= len(data):\n",
        "        model.fit(history)\n",
        "        pred = model.predict(horizon)\n",
        "        predictions.append(pred)\n",
        "        history = data.iloc[:len(history)+1]\n",
        "    return np.concatenate(predictions)\n",
        "\n",
        "# Error metrics\n",
        "def smape(actual, forecast):\n",
        "    return 100 * np.mean(2 * np.abs(forecast - actual) / (np.abs(actual) + np.abs(forecast)))\n",
        "\n",
        "def rmsse(actual, forecast, train):\n",
        "    return np.sqrt(np.mean((forecast - actual)**2) / np.mean(np.diff(train)**2))"
      ],
      "metadata": {
        "id": "WUA_5zPnwUMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and forecast\n",
        "for name, Model in models.items():\n",
        "    model = Model()\n",
        "    start_time = time.time()\n",
        "    model_params[name] = model.get_params() if hasattr(model, 'get_params') else 'N/A'\n",
        "    for horizon in [3, 6, 12]:\n",
        "        forecast = rolling_origin_forecast(model, train_data, test_data, horizon)\n",
        "        forecasts[horizon][name] = forecast\n",
        "        actuals = test_data[:len(forecast)]\n",
        "        errors['RMSE'][horizon][name] = np.sqrt(mean_squared_error(actuals, forecast))\n",
        "        errors['sMAPE'][horizon][name] = smape(actuals, forecast)\n",
        "        errors['RMSSE'][horizon][name] = rmsse(actuals, forecast, train_data)\n",
        "    train_times[name] = time.time() - start_time"
      ],
      "metadata": {
        "id": "xdiGPSLKwdmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot forecasts\n",
        "fig, axs = plt.subplots(3, 1, figsize=(12, 18))\n",
        "plots = []\n",
        "for i, horizon in enumerate([3, 6, 12]):\n",
        "    ax = axs[i]\n",
        "    ax.plot(data.index, data['Passengers'], label='Actual')\n",
        "    for name in models.keys():\n",
        "        ax.plot(test_data.index[:len(forecasts[horizon][name])], forecasts[horizon][name], label=f'{name} Forecast')\n",
        "    ax.set_title(f'{horizon}-step ahead forecasts')\n",
        "    ax.legend()\n",
        "    fig_path = f'forecast_{horizon}_steps.png'\n",
        "    plots.append(fig_path)\n",
        "    fig.savefig(fig_path)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NljvsMF4wjNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to Excel\n",
        "with pd.ExcelWriter('forecast_results.xlsx') as writer:\n",
        "    # Save forecasts\n",
        "    for horizon in [3, 6, 12]:\n",
        "        forecast_df = pd.DataFrame(forecasts[horizon])\n",
        "        forecast_df.to_excel(writer, sheet_name=f'{horizon}_step_forecasts')\n",
        "\n",
        "    # Save error metrics\n",
        "    for metric in errors.keys():\n",
        "        error_df = pd.DataFrame(errors[metric])\n",
        "        error_df.to_excel(writer, sheet_name=f'{metric}_errors')\n",
        "\n",
        "    # Save training times\n",
        "    train_times_df = pd.DataFrame(list(train_times.items()), columns=['Model', 'TrainTime'])\n",
        "    train_times_df.to_excel(writer, sheet_name='Training_Times', index=False)\n",
        "\n",
        "    # Save model parameters\n",
        "    params_df = pd.DataFrame(list(model_params.items()), columns=['Model', 'Parameters'])\n",
        "    params_df.to_excel(writer, sheet_name='Model_Params', index=False)\n",
        "\n",
        "    # Save plots\n",
        "    for fig_path in plots:\n",
        "        writer.book.add_image(fig_path, name=fig_path)\n",
        "\n",
        "# Print error metrics and training times\n",
        "for metric, results in errors.items():\n",
        "    print(f\"\\n{metric}:\")\n",
        "    for horizon, model_errors in results.items():\n",
        "        for name, error in model_errors.items():\n",
        "            print(f\"Model: {name}, Horizon: {horizon} - {metric}: {error}\")\n",
        "\n",
        "print(\"\\nTraining Times:\")\n",
        "for name, t in train_times.items():\n",
        "    print(f\"Model: {name} - Time to Train: {t}"
      ],
      "metadata": {
        "id": "6GHoc5Uowp_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}